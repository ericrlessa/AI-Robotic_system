{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (25.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-sort-realtime in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from deep-sort-realtime) (2.1.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from deep-sort-realtime) (1.15.2)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from deep-sort-realtime) (4.11.0.86)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deep-sort-realtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (8.3.100)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from opencv-python) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/yolo_deployment/lib/python3.12/site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from flask import Flask, Response, render_template\n",
    "import threading\n",
    "from camera_functions import yolo_results, yolo_ds_draw, yolo_ds_model_initalize, yolo_ds_update\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, class_names, tracker = yolo_ds_model_initalize(model_name = \"yolo11n.pt\", max_age= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_lock = threading.Lock()\n",
    "latest_frame = None\n",
    "annotated_frame = None\n",
    "last_detections = []\n",
    "frame_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_process():\n",
    "    global latest_frame, annotated_frame, last_detections, frame_count\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        with frame_lock:\n",
    "            latest_frame = frame.copy()\n",
    "\n",
    "            if frame_count % 2 == 0:\n",
    "                # Run YOLO detection every 2nd frame\n",
    "                results = yolo_results(model, frame)\n",
    "                last_detections = yolo_ds_update(frame, results, tracker)\n",
    "            annotated_frame = yolo_ds_draw(frame, last_detections, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ip_address():\n",
    "    hostname = socket.gethostname()  # Get the hostname of the server\n",
    "    ip_address = socket.gethostbyname(hostname)  # Resolve the IP address of the hostname\n",
    "    return ip_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    ip_address = get_ip_address()\n",
    "    return render_template('index_test_yolo.html', ip_address = ip_address)  # Serve the HTML page\n",
    "\n",
    "# Function to generate video frames for Flask streaming\n",
    "def generate():\n",
    "    global annotated_frame\n",
    "    while True:\n",
    "        with frame_lock:\n",
    "            if annotated_frame is None:\n",
    "                continue\n",
    "            ret, buffer = cv2.imencode('.jpg', annotated_frame)\n",
    "            if not ret:\n",
    "                continue\n",
    "            frame_bytes = buffer.tobytes()\n",
    "\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame_bytes + b'\\r\\n\\r\\n')\n",
    "\n",
    "# Flask route to serve video stream\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4000\n",
      " * Running on http://192.168.8.60:4000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2025-04-03 04:32:49.901 python[70079:14149909] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 113.2ms\n",
      "Speed: 4.9ms preprocess, 113.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 72.8ms\n",
      "Speed: 2.2ms preprocess, 72.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 85.5ms\n",
      "Speed: 3.0ms preprocess, 85.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 49.8ms\n",
      "Speed: 2.5ms preprocess, 49.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 86.5ms\n",
      "Speed: 12.6ms preprocess, 86.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 66.4ms\n",
      "Speed: 2.9ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 50.2ms\n",
      "Speed: 1.7ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 96.4ms\n",
      "Speed: 3.0ms preprocess, 96.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 45.9ms\n",
      "Speed: 1.4ms preprocess, 45.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 44.1ms\n",
      "Speed: 2.3ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Apr/2025 04:32:56] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.8.60 - - [03/Apr/2025 04:32:56] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 tie, 43.7ms\n",
      "Speed: 1.7ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 43.1ms\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 43.9ms\n",
      "Speed: 1.4ms preprocess, 43.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 78.8ms\n",
      "Speed: 1.7ms preprocess, 78.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 44.1ms\n",
      "Speed: 2.2ms preprocess, 44.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 35.6ms\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 77.0ms\n",
      "Speed: 7.6ms preprocess, 77.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 50.8ms\n",
      "Speed: 2.0ms preprocess, 50.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 70.6ms\n",
      "Speed: 3.5ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 40.1ms\n",
      "Speed: 2.3ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 56.2ms\n",
      "Speed: 6.0ms preprocess, 56.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 53.7ms\n",
      "Speed: 2.3ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 46.8ms\n",
      "Speed: 3.1ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 66.3ms\n",
      "Speed: 1.8ms preprocess, 66.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 57.7ms\n",
      "Speed: 2.3ms preprocess, 57.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 64.8ms\n",
      "Speed: 1.4ms preprocess, 64.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 46.7ms\n",
      "Speed: 2.6ms preprocess, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 57.6ms\n",
      "Speed: 2.6ms preprocess, 57.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 55.3ms\n",
      "Speed: 2.7ms preprocess, 55.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 2.1ms preprocess, 71.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 48.9ms\n",
      "Speed: 1.8ms preprocess, 48.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 44.7ms\n",
      "Speed: 1.6ms preprocess, 44.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 50.1ms\n",
      "Speed: 2.4ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 57.7ms\n",
      "Speed: 1.7ms preprocess, 57.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 49.9ms\n",
      "Speed: 1.9ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 50.4ms\n",
      "Speed: 2.7ms preprocess, 50.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 2.3ms preprocess, 76.0ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 50.2ms\n",
      "Speed: 1.8ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 41.2ms\n",
      "Speed: 1.9ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 48.3ms\n",
      "Speed: 2.6ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 40.5ms\n",
      "Speed: 3.1ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 45.8ms\n",
      "Speed: 2.4ms preprocess, 45.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 45.4ms\n",
      "Speed: 1.7ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 60.8ms\n",
      "Speed: 10.5ms preprocess, 60.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 44.7ms\n",
      "Speed: 5.5ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 57.9ms\n",
      "Speed: 1.7ms preprocess, 57.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 78.2ms\n",
      "Speed: 3.0ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 60.4ms\n",
      "Speed: 1.7ms preprocess, 60.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 79.3ms\n",
      "Speed: 2.2ms preprocess, 79.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 79.1ms\n",
      "Speed: 1.9ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 68.3ms\n",
      "Speed: 2.3ms preprocess, 68.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 52.9ms\n",
      "Speed: 2.8ms preprocess, 52.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 76.2ms\n",
      "Speed: 1.8ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 50.7ms\n",
      "Speed: 1.9ms preprocess, 50.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 312.9ms\n",
      "Speed: 3.0ms preprocess, 312.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 chair, 96.1ms\n",
      "Speed: 2.1ms preprocess, 96.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 134.3ms\n",
      "Speed: 3.3ms preprocess, 134.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 87.1ms\n",
      "Speed: 2.9ms preprocess, 87.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 54.4ms\n",
      "Speed: 2.7ms preprocess, 54.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=capture_and_process, daemon=True).start()\n",
    "\n",
    "    # Run Flask server\n",
    "    app.run(host='0.0.0.0', port=4000, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
